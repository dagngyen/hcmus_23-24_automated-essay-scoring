{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhWpr1hQp5xGweSVQ3lDtE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iam-Dylan/automated-essay-scoring/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Learning Agency Lab - Automated Essay Scoring 2.0\n",
        "\n",
        "- Môn học: Phân tích dữ liệu thông minh\n",
        "- Nhóm: 10"
      ],
      "metadata": {
        "id": "qTAFQGQWIZFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **THỬ NGHIỆM TRÊN MÔ HÌNH TỰ XÂY DỰNG**"
      ],
      "metadata": {
        "id": "w9ye0IR1Iaxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **A. Tiền xử lý dữ liệu**\n"
      ],
      "metadata": {
        "id": "MGip9Xm2IuiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Import các thư viện cần thiết**"
      ],
      "metadata": {
        "id": "0tMPXFc_I9F2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Cài đặt thư viện cần thiết."
      ],
      "metadata": {
        "id": "-B6wXtEdJNtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOi9z3txJwwh",
        "outputId": "76b9910e-ddb6-411c-eaad-14ad3cc29428"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.52.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from sklearn.svm import SVR\n",
        "import tensorflow as tf\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from spellchecker import SpellChecker\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "2cVh9YalJ4sI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DoUaG3ctKeoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL tải xuống trực tiếp của tệp CSV trên Google Drive\n",
        "TRAIN_ID = '1hUhF4f-gGTixo_-b-ytez01_swNBslIG'\n",
        "url = f\"https://drive.google.com/uc?export=download&id={TRAIN_ID}\"\n",
        "# Đọc tệp CSV từ URL\n",
        "try:\n",
        "    train = pd.read_csv(url)\n",
        "    display(train.head())\n",
        "except Exception as e:\n",
        "    print(f\"Đã xảy ra lỗi: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YJqhfIpuKgf-",
        "outputId": "14d7b6b1-916a-4712-8238-f976fbc342be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  essay_id                                          full_text  score\n",
              "0  000d118  Many people have car where they live. The thin...      3\n",
              "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
              "2  001ab80  People always wish they had the same technolog...      4\n",
              "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
              "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-974ea2f4-c62a-4a41-b98a-5f422015aef6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001bdc0</td>\n",
              "      <td>We all heard about Venus, the planet without a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002ba53</td>\n",
              "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-974ea2f4-c62a-4a41-b98a-5f422015aef6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-974ea2f4-c62a-4a41-b98a-5f422015aef6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-974ea2f4-c62a-4a41-b98a-5f422015aef6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11462ba6-d088-4ac6-a0c0-6032c8bf3fe7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11462ba6-d088-4ac6-a0c0-6032c8bf3fe7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11462ba6-d088-4ac6-a0c0-6032c8bf3fe7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"\\u0110\\u00e3 x\\u1ea3y ra l\\u1ed7i: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"000fe60\",\n          \"002ba53\",\n          \"001ab80\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I am a scientist at NASA that is discussing the \\\"face\\\" on mars. I will be explaining how the \\\"face\\\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are weird here in America, and there is also landforms all around the whole Earth. Many of them look like something we can relate to like a snake a turtle a human... So if there are landforms on earth dont you think landforms are on mars to? Of course! why not? It's just unique that the landform on Mars looks like a human face. Also if there was martians and they were trying to get our attention dont you think we would have saw one by now?\\n\\nFinaly, why you should listen to me. You should listen to me because i am a member of NASA and i've been dealing with all of this stuff that were talking about and people who say martians did this have no relation with NASA and have never worked with anything to relate to this landform. One last thing is that everyone working at NASA says the same thing i say, that the \\\"face\\\" is just a landform.\\n\\nTo sum all this up the \\\"face\\\" on mars is a landform but others would like to beleive it's a martian sculpture. Which every one that works at NASA says it's a landform and they are all the ones working on the planet and taking pictures.\",\n          \"Dear, State Senator\\n\\nThis is a letter to argue in favor of keeping the Electoral College.\\\"There are many reasons to keep the Electoral College\\\" one reason is because it is widely regarded as an anachronism, a dispute over the outcome of an Electoral College vote is possible, but it is less likely than a dispute over the popular vote, and the Electoral College restores some of the weight in the political balance that large states (by population) lose by virue of the mal apportionment of the Senate decreed in the Constitution.\\n\\nI am in favor of keeping the Electoral College because,it is widely regarded as an anachronism. A non-democratic method of selecting a president that ought to be [overruled] by declaring the canaditdate who receives the most populare votes the winner. The advocates of this position are correct in arguing that the Electoral College method is not democratic in a method sense.It is the electors who elect the the president ,not the people. But each party selects a slate of electors trusted to vote for the party's nominee (and that trust is rarely betrayed).\\n\\nAnother, reason I am in favor of keeping the Electoral College is because, a dispute over the outcome of an Electoral College vote is possible. But it is less likely than a dispute over the popular vote. But it is less likely than a dispute over the popular vote. The reason is that the winning canadate's share of the Electoral College invariably exceeds his share of the popular vote.\\n\\nLast but not least, I am in favor of keeping the Electoral College is because, the Electoral College restores some of the weight in the political balance that large states (by population) lose by virue of the mal apportionment of the Senate decreed in the Constitution. A larger state gets more attintion from presidential canadidates in a campaign than a small state does. It can be argued that Electoral College methods of selecting the president may turn off potential voters for a canadidates who has no hope of carrying their state. But of  course no voter's vote swings a national election, and in spite of that, about 1/2 the eligible American population did vote in the [2012's] election.\\n\\nFrom, PROPER_NAME            \",\n          \"People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this new technology in cars has a very long way to go before being completely \\\"driverless\\\". Drivers still need to be on alert when they are driving, as well as control the car near any accidents or complicated traffic situations. This seems to totally defeat the purpose of the \\\"driverless\\\" car. Eventually the technology may improve, but nobody can be certain that the driverless car will eventually become completely \\\"driverless\\\". This idea just seems like a lot of hard work and money for something that is not very neccessary. If someone does not want to drive their car they can just take a city bus or a subway. There are so many options of transportation that can already solve this problem. Even if masnufacturers are trying to make driving more \\\"fun\\\", driving is not meant to be \\\"fun\\\" it is meant to get people where they need to go. Playing around in a car just to have \\\"fun\\\" is just a recipe for disaster.\\n\\nThe idea of the driverless car also raises many questions about who will be liable when someone gets into an accident in one of these new cars. Many states do not even let people drive semi-automatic cars because there are not even laws that pertain to the liability of anyone who get into an accident while driving these type of cars. If these cars become more popular, states may pass new laws. However, this topic also raises questions about who is able to dictate whether or not it was the car or the human's fault for an accident. Since this technology is so new, there could be many problems with the car's system that nobody has even discovered since they have not drove the car themselves. If someone test drives this kind of car or even purchases one and they get into a crash not knowing what could possibly happen to them, they will want to sue the car manufacturer since they were not aware of any bugs in the car's system. These lawsuits can add up and eventually the manufactuers will be in a bunch of debt, which could cost them their whole idea of the driverless car.\\n\\nThe technology car manufacturers are trying to develope may just be a diasaster in the making. There are many alternative options of transportations if you do not feel like driving yourself, and these options are way less expensive than buying a brand new car. Although this technology is relatively new, we can not be certain that this new idea will even pay off in the end, it may just be a waste of money and time. Sometimes the newest technology is not the most benefical.         \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_ID = '1kJa0kIeP0RpAFFcKa1QpFP7o4xtpxjet'\n",
        "url = f\"https://drive.google.com/uc?export=download&id={TEST_ID}\"\n",
        "# Đọc tệp CSV từ URL\n",
        "try:\n",
        "    test = pd.read_csv(url)\n",
        "    display(test.head())\n",
        "except Exception as e:\n",
        "    print(f\"Đã xảy ra lỗi: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "l16vEJDYMFnn",
        "outputId": "5bbe11dd-ff64-44c0-d6eb-dc97f518d807"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  essay_id                                          full_text\n",
              "0  000d118  Many people have car where they live. The thin...\n",
              "1  000fe60  I am a scientist at NASA that is discussing th...\n",
              "2  001ab80  People always wish they had the same technolog..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8af1370-7566-4260-8c65-60c15a277221\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8af1370-7566-4260-8c65-60c15a277221')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8af1370-7566-4260-8c65-60c15a277221 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8af1370-7566-4260-8c65-60c15a277221');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e53f6a5-c853-40c6-a89a-f0966e1ac568\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e53f6a5-c853-40c6-a89a-f0966e1ac568')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e53f6a5-c853-40c6-a89a-f0966e1ac568 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"\\u0110\\u00e3 x\\u1ea3y ra l\\u1ed7i: {e}\\\")\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"000d118\",\n          \"000fe60\",\n          \"001ab80\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happen\\u00a0like you can get in accidet or\\u00a0the smoke that the car has is bad to breath\\u00a0on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden\\u00a0on the outskirts of freiburd that near the French and Swiss borders. You probaly won't see a car in Vauban's streets because they are completely \\\"car free\\\" but\\u00a0If some that lives in VAUBAN that owns a car ownership is allowed,but there are only two places that you can park a large garages at the edge of the development,where a car owner buys a space but it not cheap to buy one they sell the space for you car for $40,000 along with a home. The vauban people completed this in 2006 ,they said that this an example of a growing trend in Europe,The untile states and some where else are suburban life from auto use this is called \\\"smart planning\\\". The current efforts to drastically reduce greenhouse gas emissions from tailes the passengee cars are responsible for 12 percent of greenhouse gas emissions in Europe and up to 50 percent in some car intensive in the United States. I honeslty think that good idea that they did that is Vaudan because that makes cities denser and better for walking and in VAUBAN there are 5,500 residents within a rectangular square mile. In the artical David Gold berg said that \\\"All of our development since World war 2 has been centered on the cars,and that will have to change\\\" and i think that was very true what David Gold said because alot thing we need cars to do we can go anyway were with out cars beacuse some people are a very lazy to walk to place thats why they alot of people use car and i think that it was a good idea that that they did that in VAUBAN so people can see how we really don't need car to go to place from place because we can walk from were we need to go or we can ride bycles with out the use of a car. It good that they are doing that if you thik about your help the earth in way and thats a very good thing to. In the United states ,the Environmental protection Agency is promoting what is called \\\"car reduced\\\"communtunties,and the legislators are starting to act,if cautiously. Maany experts expect pubic transport serving suburbs to play a much larger role in a new six years federal transportation bill to approved this year. In previous bill,80 percent of appropriations have by law gone to highways and only 20 percent to other transports. There many good reason why they should do this.    \",\n          \"I am a scientist at NASA that is discussing the \\\"face\\\" on mars. I will be explaining how the \\\"face\\\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are weird here in America, and there is also landforms all around the whole Earth. Many of them look like something we can relate to like a snake a turtle a human... So if there are landforms on earth dont you think landforms are on mars to? Of course! why not? It's just unique that the landform on Mars looks like a human face. Also if there was martians and they were trying to get our attention dont you think we would have saw one by now?\\n\\nFinaly, why you should listen to me. You should listen to me because i am a member of NASA and i've been dealing with all of this stuff that were talking about and people who say martians did this have no relation with NASA and have never worked with anything to relate to this landform. One last thing is that everyone working at NASA says the same thing i say, that the \\\"face\\\" is just a landform.\\n\\nTo sum all this up the \\\"face\\\" on mars is a landform but others would like to beleive it's a martian sculpture. Which every one that works at NASA says it's a landform and they are all the ones working on the planet and taking pictures.\",\n          \"People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this new technology in cars has a very long way to go before being completely \\\"driverless\\\". Drivers still need to be on alert when they are driving, as well as control the car near any accidents or complicated traffic situations. This seems to totally defeat the purpose of the \\\"driverless\\\" car. Eventually the technology may improve, but nobody can be certain that the driverless car will eventually become completely \\\"driverless\\\". This idea just seems like a lot of hard work and money for something that is not very neccessary. If someone does not want to drive their car they can just take a city bus or a subway. There are so many options of transportation that can already solve this problem. Even if masnufacturers are trying to make driving more \\\"fun\\\", driving is not meant to be \\\"fun\\\" it is meant to get people where they need to go. Playing around in a car just to have \\\"fun\\\" is just a recipe for disaster.\\n\\nThe idea of the driverless car also raises many questions about who will be liable when someone gets into an accident in one of these new cars. Many states do not even let people drive semi-automatic cars because there are not even laws that pertain to the liability of anyone who get into an accident while driving these type of cars. If these cars become more popular, states may pass new laws. However, this topic also raises questions about who is able to dictate whether or not it was the car or the human's fault for an accident. Since this technology is so new, there could be many problems with the car's system that nobody has even discovered since they have not drove the car themselves. If someone test drives this kind of car or even purchases one and they get into a crash not knowing what could possibly happen to them, they will want to sue the car manufacturer since they were not aware of any bugs in the car's system. These lawsuits can add up and eventually the manufactuers will be in a bunch of debt, which could cost them their whole idea of the driverless car.\\n\\nThe technology car manufacturers are trying to develope may just be a diasaster in the making. There are many alternative options of transportations if you do not feel like driving yourself, and these options are way less expensive than buying a brand new car. Although this technology is relatively new, we can not be certain that this new idea will even pay off in the end, it may just be a waste of money and time. Sometimes the newest technology is not the most benefical.         \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Tiền xử lý dữ liệu**\n",
        "\n",
        "Cần **làm sạch văn bản**, nhằm chuẩn hóa và loại bỏ những thành phần không cần thiết trước khi tiến hành các bước xử lý tiếp theo.\n",
        "\n",
        "- Văn bản được chuyển đổi toàn bộ về **chữ thường** để đảm bảo tính nhất quán và tránh phân biệt giữa chữ hoa và chữ thường.\n",
        "- Các **thẻ HTML**, thẻ tên người dùng (bắt đầu bằng @), **hashtag** (bắt đầu bằng #), và đường dẫn **URL** đều được loại bỏ để giữ lại nội dung văn bản thực sự.\n",
        "- Các **ký tự đặc biệt** và các **số** trong văn bản, thường không mang lại giá trị ngữ nghĩa, cũng được loại bỏ.\n",
        "- Các **dấu câu liên tiếp** được xử lý và thay thế bằng một ký tự duy nhất.\n",
        "- Các **từ viết tắt** được mở rộng thành dạng đầy đủ để đảm bảo tính nhất quán. Tham khảo từ: [Expand Contractions](https://www.kaggle.com/code/xianhellg/more-feature-engineering-feature-selection-0-817?scriptVersionId=173223907&cellId=11)"
      ],
      "metadata": {
        "id": "2vKR0W2eMgo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_contractions(text):\n",
        "    # Mở rộng các từ viết tắt.\n",
        "    contractions_dict = {\n",
        "    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\n",
        "    \"it'd\": \"it had\",\n",
        "    \"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\"so's\": \"so is\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\"that's\": \"that is\",\n",
        "    \"there'd\": \"there had\",\n",
        "    \"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\"wasn't\": \"was not\",\"weren't\": \"were not\",\n",
        "    \"we'd\": \"we had\",\n",
        "    \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
        "    \"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\n",
        "    \"you're\": \"you are\",  \"you've\": \"you have\"\n",
        "    }\n",
        "    contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "    return contractions_re.sub(lambda match: contractions_dict[match.group(0)], text)\n",
        "\n",
        "def clean_text(text):\n",
        "    # Chuyển chữ viết hoa thành chữ thường\n",
        "    text = text.lower()\n",
        "\n",
        "    # Xóa các thẻ HTML\n",
        "    text = re.compile(r'<.*?>').sub(r'', text)\n",
        "\n",
        "    # Xóa các tag tên (mention)\n",
        "    text = re.sub(r'@\\w+\\s*', '', text)\n",
        "\n",
        "    # Xóa hashtag (dấu #)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Xóa các liên kết URL\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "\n",
        "    # Xóa các ký tự không mong muốn như \\xa0\n",
        "    text = text.replace(u'\\xa0', ' ')\n",
        "\n",
        "    # Xóa chữ số\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Mở rộng các từ viết tắt\n",
        "    text = expand_contractions(text)\n",
        "\n",
        "    # Thay thế các dấu chấm và dấu phẩy liên tiếp bằng một dấu duy nhất\n",
        "    text = re.sub(r'\\.+', '.', text)\n",
        "    text = re.sub(r'\\,+', ',', text)\n",
        "\n",
        "    # Xóa các khoảng trắng ở đầu và cuối chuỗi\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "train['full_text'] = train['full_text'].apply(clean_text)\n",
        "test['full_text'] = test['full_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "TdS3isTiMlw_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Feature engineering**"
      ],
      "metadata": {
        "id": "IS4C5oFwOXtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rút trích đặc trưng đoạn văn**\n",
        "\n",
        "Phân tích về đặc trưng đoạn văn giúp hiểu rõ hơn về cấu trúc văn bản, độ phức tạp và ngữ cảnh văn bản.\n",
        "- Độ dài đoạn văn phản ánh mức độ chi tiết và độ phức tạp của văn bản.\n",
        "- Số câu trong đoạn văn giúp xác định mức độ chi tiết và cách trình bày của văn bản.\n",
        "- Số từ trong đoạn văn là một chỉ số quan trọng để đo lường độ phức tạp và độ dài của văn bản.\n",
        "- Lấy giá trị đầu tiên và cuối cùng của mỗi đặc trưng  giúp hiểu thêm về sự biến đổi và xu hướng của các đoạn văn trong văn bản.\n"
      ],
      "metadata": {
        "id": "T6d3qJYIPOmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_paragraph_features(data):\n",
        "    # Step 1: Process data to extract paragraphs\n",
        "    data['paragraph'] = data['full_text'].str.split('\\n\\n')\n",
        "\n",
        "    # Step 2: Preprocess paragraphs\n",
        "    data = data.explode('paragraph')\n",
        "    data = data[data['paragraph'].str.strip() != \"\"]\n",
        "    data['paragraph'] = data['paragraph'].apply(clean_text)\n",
        "    data['paragraph_length'] = data['paragraph'].apply(len)\n",
        "    data['sentence_count'] = data['paragraph'].apply(lambda x: len(x.split('.')))\n",
        "    data['word_count'] = data['paragraph'].apply(lambda x: len(x.split()))\n",
        "    data['fullstop_ratio'] = data.apply(lambda row: row['paragraph'].count('.') / len(row['paragraph']) if len(row['paragraph']) > 0 else 0, axis=1)\n",
        "\n",
        "    # Step 3: Calculate features\n",
        "    features = ['paragraph_length', 'sentence_count', 'word_count']\n",
        "\n",
        "    # Group by essay_id and calculate the necessary aggregations\n",
        "    def calculate_aggregations(group):\n",
        "        aggs = {}\n",
        "        for feat in features:\n",
        "            aggs[f'{feat}_max'] = group[feat].max()\n",
        "            aggs[f'{feat}_mean'] = group[feat].mean()\n",
        "            aggs[f'{feat}_min'] = group[feat].min()\n",
        "            aggs[f'{feat}_first'] = group[feat].iloc[0]\n",
        "            aggs[f'{feat}_last'] = group[feat].iloc[-1]\n",
        "            aggs[f'{feat}_sum'] = group[feat].sum()\n",
        "            aggs[f'{feat}_q1'] = group[feat].quantile(0.25)\n",
        "            aggs[f'{feat}_med'] = group[feat].median()\n",
        "            aggs[f'{feat}_q3'] = group[feat].quantile(0.75)\n",
        "\n",
        "        length_counts = {f'length_ge_{i}_count': (group['paragraph_length'] >= i).sum() for i in [50, 75, 100, 125, 150, 175, 200, 250, 300, 350, 400, 500, 600, 700]}\n",
        "        length_counts.update({f'length_le_{i}_count': (group['paragraph_length'] <= i).sum() for i in [25, 49]})\n",
        "\n",
        "        aggs.update(length_counts)\n",
        "\n",
        "        return pd.Series(aggs)\n",
        "\n",
        "    data = data.groupby('essay_id').apply(calculate_aggregations).reset_index()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Sử dụng hàm để xử lý dữ liệu train và test\n",
        "train_feats = extract_paragraph_features(train)\n",
        "test_feats = extract_paragraph_features(test)\n",
        "\n",
        "# Đếm số đặc trưng\n",
        "feature_names = [col for col in train_feats.columns if col not in ['essay_id', 'score']]\n",
        "print('Feature count in train set: ', len(feature_names))\n",
        "\n",
        "feature_names = [col for col in test_feats.columns if col not in ['essay_id', 'score']]\n",
        "print('Feature count in test set: ', len(feature_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqF1fzvSZ7P",
        "outputId": "e91033b6-405d-4ed2-8819-9522dba7ac01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count in train set:  43\n",
            "Feature count in test set:  43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rút trích đặc trưng câu văn**\n",
        "\n",
        "Tương tự, việc phân tích về đặc trưng câu văn cũng giúp hiểu rõ hơn về cấu trúc, độ phức tạp và ngữ cảnh văn bản.\n",
        "\n",
        "- Độ dài câu văn phản ánh mức độ chi tiết của thông tin và độ phức tạp trong cấu trúc câu.\n",
        "- Giá trị đầu tiên và cuối cùng của mỗi đặc trưng giúp hiểu thêm về sự biến đổi và xu hướng của các câu văn trong văn bản.\n",
        "- Giá trị phân vị của các đặc trưng phản ánh mức độ phân tán và sự biến động trong độ dài và số lượng từ của các câu văn."
      ],
      "metadata": {
        "id": "CUF3mYf0WMKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentence_features(data):\n",
        "    # Step 1: Preprocess sentences\n",
        "    data['sentence'] = data['full_text'].apply(clean_text).str.split('.')\n",
        "    data = data.explode('sentence')\n",
        "    data['sentence_len'] = data['sentence'].apply(len)\n",
        "    data = data[data['sentence_len'] >= 15]\n",
        "    data['sentence_word_count'] = data['sentence'].apply(lambda x: len(x.split()))\n",
        "    data['comma_ratio'] = data['sentence'].apply(lambda x: x.count(',') / len(x) if len(x) > 0 else 0)\n",
        "\n",
        "    features = ['sentence_len', 'sentence_word_count']\n",
        "\n",
        "    # Step 2: Calculate features\n",
        "    def calculate_aggregations(group):\n",
        "        aggs = {}\n",
        "        for feat in features:\n",
        "            aggs[f'{feat}_max'] = group[feat].max()\n",
        "            aggs[f'{feat}_mean'] = group[feat].mean()\n",
        "            aggs[f'{feat}_min'] = group[feat].min()\n",
        "            aggs[f'{feat}_first'] = group[feat].iloc[0]\n",
        "            aggs[f'{feat}_last'] = group[feat].iloc[-1]\n",
        "            aggs[f'{feat}_sum'] = group[feat].sum()\n",
        "            aggs[f'{feat}_q1'] = group[feat].quantile(0.25)\n",
        "            aggs[f'{feat}_med'] = group[feat].median()\n",
        "            aggs[f'{feat}_q3'] = group[feat].quantile(0.75)\n",
        "\n",
        "        sentence_length_counts = {f'sentence_length_ge_{i}_count': (group['sentence_len'] >= i).sum() for i in [15, 50, 100, 150, 200, 250, 300]}\n",
        "\n",
        "        aggs.update(sentence_length_counts)\n",
        "\n",
        "        return pd.Series(aggs)\n",
        "\n",
        "    data = data.groupby('essay_id').apply(calculate_aggregations).reset_index()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Xử lý dữ liệu train và test\n",
        "sentence_train = extract_sentence_features(train)\n",
        "sentence_test = extract_sentence_features(test)\n",
        "\n",
        "# Kết hợp các đặc trưng mới vào dữ liệu\n",
        "train_feats = train_feats.merge(sentence_train, on='essay_id', how='left')\n",
        "test_feats = test_feats.merge(sentence_test, on='essay_id', how='left')\n",
        "\n",
        "# Đếm số đặc trưng\n",
        "feature_names = [col for col in train_feats.columns if col not in ['essay_id', 'score']]\n",
        "print('Feature count in train set: ', len(feature_names))\n",
        "\n",
        "feature_names = [col for col in test_feats.columns if col not in ['essay_id', 'score']]\n",
        "print('Feature count in test set: ', len(feature_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhjO_VTaWf14",
        "outputId": "2855368e-583a-4cf7-cb7b-1cb0e8ee8da5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count in train set:  68\n",
            "Feature count in test set:  68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rút trích đặc trưng từ**\n",
        "\n",
        "- Độ dài từ phản ánh mức độ phức tạp, tính học thuật và mức độ thông tin của từ vựng sử dụng trong văn bản.\n",
        "- Giá trị lớn nhất, trung bình, độ lệch chuẩn, và các phần tư cung cấp cái nhìn tổng quát về sự phân bố độ dài từ trong văn bản.\n",
        "- Số lượng lỗi chính tả cho biết về chất lượng từ vựng và khả năng biểu đạt của văn bản."
      ],
      "metadata": {
        "id": "iX0vJj0JrQP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_word_features(data):\n",
        "    spellchecker = SpellChecker()\n",
        "    data['word'] = data['full_text'].apply(clean_text).str.split(' ')\n",
        "    data = data.explode('word')\n",
        "    data['word_len'] = data['word'].apply(len)\n",
        "    data = data[data['word_len'] != 0]\n",
        "\n",
        "    # Thêm cột 'spelling_error' để xác định lỗi chính tả\n",
        "    def is_spelling_error(word):\n",
        "        return word in spellchecker.unknown([word])\n",
        "\n",
        "    data['is_spelling_error'] = data['word'].apply(is_spelling_error)\n",
        "\n",
        "    def calculate_aggregations(group):\n",
        "        aggs = {}\n",
        "\n",
        "        feat = 'word_len'\n",
        "        aggs[f'{feat}_max'] = group[feat].max()\n",
        "        aggs[f'{feat}_mean'] = group[feat].mean()\n",
        "        aggs[f'{feat}_min'] = group[feat].min()\n",
        "        aggs[f'{feat}_first'] = group[feat].iloc[0]\n",
        "        aggs[f'{feat}_last'] = group[feat].iloc[-1]\n",
        "        aggs[f'{feat}_sum'] = group[feat].sum()\n",
        "        aggs[f'{feat}_q1'] = group[feat].quantile(0.25)\n",
        "        aggs[f'{feat}_med'] = group[feat].median()\n",
        "        aggs[f'{feat}_q3'] = group[feat].quantile(0.75)\n",
        "\n",
        "        aggs['spelling_errors_count'] = group['is_spelling_error'].sum()\n",
        "\n",
        "        word_length_counts = {f'word_length_ge_{i+1}_count': (group['word_len'] >= i+1).sum() for i in range(15)}\n",
        "        aggs.update(word_length_counts)\n",
        "\n",
        "        return pd.Series(aggs)\n",
        "\n",
        "    data = data.groupby('essay_id').apply(calculate_aggregations).reset_index()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Xử lý dữ liệu train và test\n",
        "word_train = extract_word_features(train)\n",
        "word_test = extract_word_features(test)\n",
        "\n",
        "# Kết hợp các đặc trưng mới vào dữ liệu\n",
        "train_feats = train_feats.merge(word_train, on='essay_id', how='left')\n",
        "test_feats = test_feats.merge(word_test, on='essay_id', how='left')\n",
        "\n",
        "# Đếm số đặc trưng\n",
        "feature_names = [col for col in train_feats.columns if col not in ['essay_id', 'score']]\n",
        "print('Feature count in train set: ', len(feature_names))\n",
        "\n",
        "feature_names = [col for col in test_feats.columns if col not in ['essay_id', 'score']]\n",
        "print('Feature count in test set: ', len(feature_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl_956SHwoPx",
        "outputId": "951c71a8-e954-477a-f03b-da6f15b469b7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count in train set:  93\n",
            "Feature count in test set:  93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Phương pháp bag-of-n-gram**\n",
        "\n",
        "Chúng ta sẽ mã hoá các cụm n-grams trong câu thành một vector có độ dài bằng số lượng các n-grams trong từ điển và đếm tần suất xuất hiện của các cụm đó. Như vậy thì mỗi cụm n-grams sẽ trở thành một chiều biểu diễn trong không gian của vector đầu ra."
      ],
      "metadata": {
        "id": "3lnvg6ry61fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo CountVectorizer với các tham số cụ thể\n",
        "vectorizer_cnt = CountVectorizer(\n",
        "            tokenizer=lambda x: x,\n",
        "            preprocessor=lambda x: x,\n",
        "            token_pattern=None,\n",
        "            strip_accents='unicode',\n",
        "            analyzer = 'word',\n",
        "            ngram_range=(2,3),\n",
        "            min_df=0.10,\n",
        "            max_df=0.85,\n",
        ")\n",
        "\n",
        "# Áp dụng CountVectorizer lên dữ liệu huấn luyện\n",
        "train_cnt = vectorizer_cnt.fit_transform([i for i in train['full_text']])\n",
        "test_cnt = vectorizer_cnt.transform([i for i in test['full_text']])\n",
        "\n",
        "# Đưa kết quả vào DataFrame\n",
        "cnt_train = pd.DataFrame(train_cnt.toarray())\n",
        "cnt_test = pd.DataFrame(test_cnt.toarray())\n",
        "\n",
        "cnt_train.columns = [f'cnt_{i}' for i in range(len(cnt_train.columns))]\n",
        "cnt_test.columns = [f'cnt_{i}' for i in range(len(cnt_test.columns))]\n",
        "cnt_train['essay_id'] = train_feats['essay_id']\n",
        "cnt_test['essay_id'] = test_feats['essay_id']\n",
        "\n",
        "# Hợp nhất các đặc trưng mới với dữ liệu huấn luyện đã có\n",
        "train_feats = train_feats.merge(cnt_train, on='essay_id', how='left')\n",
        "test_feats = test_feats.merge(cnt_test, on='essay_id', how='left')\n",
        "\n",
        "# Đếm số đặc trưng\n",
        "feature_names = list(filter(lambda x: x not in ['essay_id', 'score'], train_feats.columns))\n",
        "print('Feature count in train set: ', len(feature_names))\n",
        "\n",
        "feature_names = list(filter(lambda x: x not in ['essay_id', 'score'], test_feats.columns))\n",
        "print('Feature count in test set: ', len(feature_names))"
      ],
      "metadata": {
        "id": "PBy97Krs66YQ",
        "outputId": "896eac5a-2998-435f-ace3-ac3632e9988b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count in train set:  2081\n",
            "Feature count in test set:  2081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Phương pháp TF-IDF (Term Frequency, Inverse Document Frequency)**\n",
        "\n",
        "TF-IDF là viết tắt của “Term Frequency, Inverse Document Frequency” - tạm dịch “Tần suất thuật ngữ, Tần suất tài liệu nghịch đảo”. Đó là một cách để chấm điểm tầm quan trọng của các từ (hoặc \\\"các thuật ngữ\\\") dựa trên tần suất xuất hiện của chúng xuất hiện trên nhiều tài liệu dựa trên quy tắc sau:\n",
        "- Nếu một từ xuất hiện thường xuyên trong tài liệu, điều đó rất quan trọng $\\Rightarrow$ cho từ này điểm cao.\n",
        "- Nhưng nếu một từ xuất hiện trong nhiều tài liệu, thì đó không phải là mã định danh duy nhất $\\Rightarrow$ cho từ đó điểm thấp.\n",
        "\n",
        "Do đó, những từ phổ biến như `the` và `for` xuất hiện trong nhiều tài liệu sẽ được scaled down. Các từ xuất hiện thường xuyên trong một tài liệu sẽ được scaled up.\n",
        "\n",
        "Với những giải thích trên, ta có công thức tính trọng số của một từ trong tài liệu trong ngữ liệu như sau:\n",
        "$$w_{i,j} = tf_{i,j} \\cdot idf_i = tf_{i,j} \\cdot log(\\frac {N}{df_i})$$\n",
        "\n",
        "Trong đó:\n",
        "- $tf_{i,j}$: Tần suất xuất hiện của i trong j\n",
        "- $N$: Tổng số tài liệu\n",
        "- $df_i$: Số tài liệu chứa i\n",
        "\n",
        "Tham khảo: [An Introduction to TF-IDF using Python](https://medium.com/analytics-vidhya/an-introduction-to-tf-idf-using-python-5f9d1a343f77)"
      ],
      "metadata": {
        "id": "mrViiHWF6fm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo TfidfVectorizer với các tham số cụ thể\n",
        "vectorizer_tfidf = TfidfVectorizer(\n",
        "    tokenizer=lambda x: x,\n",
        "    preprocessor=lambda x: x,\n",
        "    token_pattern=None,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    ngram_range=(2,3),\n",
        "    min_df=0.05,\n",
        "    max_df=0.95,\n",
        "    sublinear_tf=True,\n",
        ")\n",
        "\n",
        "# Áp dụng TfidfVectorizer lên dữ liệu huấn luyện\n",
        "train_tfidf = vectorizer_tfidf.fit_transform([i for i in train['full_text']])\n",
        "test_tfidf = vectorizer_tfidf.transform([i for i in test['full_text']])\n",
        "\n",
        "# Đưa kết quả vào DataFrame\n",
        "tfidf_train = pd.DataFrame(train_tfidf.toarray())\n",
        "tfidf_test = pd.DataFrame(test_tfidf.toarray())\n",
        "\n",
        "# Đổi tên các cột\n",
        "tfidf_train.columns = [f'tfid_{i}' for i in range(len(tfidf_train.columns))]\n",
        "tfidf_test.columns = [f'tfid_{i}' for i in range(len(tfidf_test.columns))]\n",
        "tfidf_train['essay_id'] = train_feats['essay_id']\n",
        "tfidf_test['essay_id'] = test_feats['essay_id']\n",
        "\n",
        "# Hợp nhất các đặc trưng mới với dữ liệu huấn luyện đã có\n",
        "train_feats = train_feats.merge(tfidf_train, on='essay_id', how='left')\n",
        "test_feats = test_feats.merge(tfidf_test, on='essay_id', how='left')\n",
        "\n",
        "# Đếm số đặc trưng\n",
        "feature_names = list(filter(lambda x: x not in ['essay_id', 'score'], train_feats.columns))\n",
        "print('Feature count in train set: ', len(feature_names))\n",
        "\n",
        "feature_names = list(filter(lambda x: x not in ['essay_id', 'score'], test_feats.columns))\n",
        "print('Feature count in test set: ', len(feature_names))"
      ],
      "metadata": {
        "id": "YjKSmbpM8D1d",
        "outputId": "249bf3af-c2f1-4247-f5ba-6b813e0ba20d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count in train set:  4968\n",
            "Feature count in test set:  4968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **B. Xây dựng mô hình**"
      ],
      "metadata": {
        "id": "HinOYEfX8jXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Chuẩn bị dữ liệu**"
      ],
      "metadata": {
        "id": "OJkFnJD18qvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cài đặt kiểm tra chéo dữ liệu với StratifiedKFold**"
      ],
      "metadata": {
        "id": "oCZgu3cP80M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 5\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "train_feats = train_feats.merge(train, on='essay_id', how='left')\n",
        "\n",
        "for i, (_, val_index) in enumerate(skf.split(train_feats, train_feats['score'])):\n",
        "    train_feats.loc[val_index, 'fold'] = i"
      ],
      "metadata": {
        "id": "bBvFUHy48jJ6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Feature selection**"
      ],
      "metadata": {
        "id": "4jpe7_N7-IGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['score']\n",
        "drop_columns = ['essay_id', 'fold', 'full_text', 'paragraph', 'sentence', 'word']"
      ],
      "metadata": {
        "id": "qpLE_XHX-VO2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Định nghĩa hàm đánh giá và hàm mất mát**\n",
        "\n",
        "- Sử dụng **mô hình hồi quy** giúp cho việc học dữ liệu không bị overfitting. Vì thế vấn đề xảy ra khi sử dụng bài toán hồi quy cho biến dự đoán phân loại có thứ tự là xác định đúng được làm tròn số ở ngưỡng nào.\n",
        "- Giá trị nhãn được **cộng thêm giá trị trung bình** của y nhằm điều chỉnh các nhãn về trung tâm của phân phối dữ liệu, làm giảm sai lệch và giúp các nhãn có giá trị gần với trung bình của tập dữ liệu gốc.\n",
        "- Giá trị nhãn dự đoán được **giới hạn nằm trong khoảng từ 1 đến 6**, giả định rằng nhãn có giá trị trong khoảng này. Điều này giúp giữ các nhãn dự đoán trong phạm vi hợp lý và tránh các giá trị bất thường.\n"
      ],
      "metadata": {
        "id": "Gnc0a4Oy-Wwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm tính toán QWK\n",
        "def calculate_quadratic_weighted_kappa(y_true, y_pred):\n",
        "    y_true_adjusted = (y_true + a).round()\n",
        "    y_pred_adjusted = (y_pred + a).clip(1, 6).round()\n",
        "    qwk_score = cohen_kappa_score(y_true_adjusted, y_pred_adjusted, weights=\"quadratic\")\n",
        "    return 'QWK', qwk_score, True\n",
        "\n",
        "# Hàm mục tiêu cho QWK\n",
        "def qwk_objective(y_true, y_pred):\n",
        "    y_true_adjusted = y_true + a\n",
        "    y_pred_adjusted = y_pred + a\n",
        "    y_pred_adjusted = y_pred_adjusted.clip(1, 6)\n",
        "\n",
        "    f = 1 / 2 * np.sum((y_pred_adjusted - y_true_adjusted) ** 2)\n",
        "    g = 1 / 2 * np.sum((y_pred_adjusted - a) ** 2 + b)\n",
        "\n",
        "    df = y_pred_adjusted - y_true_adjusted\n",
        "    dg = y_pred_adjusted - a\n",
        "\n",
        "    grad = (df / g - f * dg / g ** 2) * len(y_true_adjusted)\n",
        "    hess = np.ones(len(y_true_adjusted))\n",
        "    return grad, hess\n",
        "\n",
        "# Hàm tính toán các tham số cho QWK\n",
        "def calculate_qwk_parameters(y):\n",
        "    mean_value = y.mean()\n",
        "    variance_value = (y ** 2).mean() - mean_value ** 2\n",
        "    return np.round(mean_value, 4), np.round(variance_value, 4)"
      ],
      "metadata": {
        "id": "W3NfoS5C-bnA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Huấn luyện mô hình**"
      ],
      "metadata": {
        "id": "xIVLEH5H-1Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mô hình Support Vector Regression**\n",
        "\n"
      ],
      "metadata": {
        "id": "SiTrfZbO6ftf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_qwk_list = []\n",
        "predictions, actuals = [], []\n",
        "\n",
        "for fold in range(K):\n",
        "    print('### Fold', fold+1)\n",
        "\n",
        "    a, b = calculate_qwk_parameters(train_feats[train_feats['fold'] != fold]['score'])\n",
        "    X_train = train_feats[train_feats[\"fold\"] != fold].drop(columns=drop_columns+target)\n",
        "    y_train = train_feats[train_feats[\"fold\"] != fold]['score'] - a\n",
        "    X_valid = train_feats[train_feats[\"fold\"] == fold].drop(columns=drop_columns+target)\n",
        "    y_valid = train_feats[train_feats[\"fold\"] == fold]['score'] - a\n",
        "\n",
        "    model = SVR(C=10)\n",
        "    model.fit(X_train, y_train)\n",
        "    train_preds = model.predict(X_valid)\n",
        "\n",
        "    actuals.extend(y_valid + a)\n",
        "    predictions.extend(np.round(train_preds + a, 0))\n",
        "\n",
        "    score_qwk_list.append(calculate_quadratic_weighted_kappa(y_valid, train_preds)[1])\n",
        "    print(f\"QWK score: {score_qwk_list[-1]}\")\n",
        "    print()\n",
        "\n",
        "validation_score = cohen_kappa_score(actuals, predictions, weights=\"quadratic\")\n",
        "print(f\"Validation score: {validation_score}\")"
      ],
      "metadata": {
        "id": "iHtGKuUU60F9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "103108c1-e686-47ed-fc36-13af6c48dafd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Fold 1\n",
            "QWK score: 0.7319516684614632\n",
            "\n",
            "### Fold 2\n",
            "QWK score: 0.7336275853002813\n",
            "\n",
            "### Fold 3\n",
            "QWK score: 0.7150840299849707\n",
            "\n",
            "### Fold 4\n",
            "QWK score: 0.7314973572962977\n",
            "\n",
            "### Fold 5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-017f8e9c4d5f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/svm/_libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm.fit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mô hình Neural Network**"
      ],
      "metadata": {
        "id": "J7DWPU6SHLMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "predictions, actuals = [], []\n",
        "\n",
        "for fold in range(5):\n",
        "    # Split the data into training and validation sets\n",
        "    a, b = calculate_qwk_parameters(train_feats[train_feats['fold'] != fold]['score'])\n",
        "    train_data = train_feats[train_feats['fold'] != fold]\n",
        "    val_data = train_feats[train_feats['fold'] == fold]\n",
        "\n",
        "    X_train_tf = train_data.drop(columns=drop_columns+target).values\n",
        "    y_train_tf = train_data['score'].values - a\n",
        "    X_val_tf = val_data.drop(columns=drop_columns+target).values\n",
        "    y_val_tf = val_data['score'].values - a\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error')\n",
        "\n",
        "    # Custom callback to calculate QWK at the end of each epoch\n",
        "    class QWKCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            y_val_pred = self.model.predict(X_val_tf).flatten()\n",
        "            qwk_score = calculate_quadratic_weighted_kappa(y_val_tf, y_val_pred)\n",
        "            print(f\"Epoch {epoch + 1} QWK: {qwk_score}\")\n",
        "\n",
        "    # Train the model with QWKCallback\n",
        "    model.fit(X_train_tf, y_train_tf, epochs=20, batch_size=80, verbose=0, callbacks=[QWKCallback()])\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    y_val_pred = model.predict(X_val_tf).flatten()\n",
        "    actuals.extend(y_val_tf + a)\n",
        "    predictions.extend(np.round(y_val_pred + a, 0))\n",
        "    val_loss = model.evaluate(X_val_tf, y_val_tf, verbose=0)\n",
        "    qwk_score = calculate_quadratic_weighted_kappa(y_val_tf, y_val_pred)\n",
        "\n",
        "    print(f\"Fold {fold}: Validation Loss = {val_loss}, QWK = {qwk_score[1]}\")\n",
        "\n",
        "# Tính toán điểm Kappa trọng số bậc hai (QWK) cho các dự đoán\n",
        "validation_score = cohen_kappa_score(actuals, predictions, weights=\"quadratic\")\n",
        "# In ra điểm đánh giá\n",
        "print(f\"Validation score: {validation_score}\")"
      ],
      "metadata": {
        "id": "Dxd3Qa5gv2Rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa177a0-5db8-47dc-d2fb-6178b83a31b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 1 QWK: ('QWK', 0.3314802226239598, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 2 QWK: ('QWK', 0.6029924506550897, True)\n",
            "109/109 [==============================] - 0s 4ms/step\n",
            "Epoch 3 QWK: ('QWK', 0.5987568377464588, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 4 QWK: ('QWK', 0.703579450422087, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 5 QWK: ('QWK', 0.4343325970800377, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 6 QWK: ('QWK', 0.6791267092788158, True)\n",
            "109/109 [==============================] - 1s 4ms/step\n",
            "Epoch 7 QWK: ('QWK', 0.7250488148934509, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 8 QWK: ('QWK', 0.7455082992314565, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 9 QWK: ('QWK', 0.6943322215738115, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 10 QWK: ('QWK', 0.7372396296601487, True)\n",
            "109/109 [==============================] - 1s 6ms/step\n",
            "Epoch 11 QWK: ('QWK', 0.644814218489147, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 12 QWK: ('QWK', 0.576774942730272, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 13 QWK: ('QWK', 0.49355565093746046, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 14 QWK: ('QWK', 0.7373675392604468, True)\n",
            "109/109 [==============================] - 0s 4ms/step\n",
            "Epoch 15 QWK: ('QWK', 0.5505010508715945, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 16 QWK: ('QWK', 0.761073885563491, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 17 QWK: ('QWK', 0.7129503870385743, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 18 QWK: ('QWK', 0.6032246004720809, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 19 QWK: ('QWK', 0.6578887004144186, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 20 QWK: ('QWK', 0.7614673327409287, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Fold 0: Validation Loss = 0.4060285985469818, QWK = 0.7614673327409287\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 1 QWK: ('QWK', 0.5642071136462522, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 2 QWK: ('QWK', 0.6281086495389525, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 3 QWK: ('QWK', 0.36012795594132097, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 4 QWK: ('QWK', 0.6729165640750574, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 5 QWK: ('QWK', 0.7043826868552396, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 6 QWK: ('QWK', 0.48680029691690696, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 7 QWK: ('QWK', 0.7190659427687631, True)\n",
            "109/109 [==============================] - 1s 9ms/step\n",
            "Epoch 8 QWK: ('QWK', 0.6371206527104604, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 9 QWK: ('QWK', 0.5039871895342565, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 10 QWK: ('QWK', 0.7119576514432377, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 11 QWK: ('QWK', 0.6632789724384197, True)\n",
            "109/109 [==============================] - 1s 6ms/step\n",
            "Epoch 12 QWK: ('QWK', 0.7666453579680941, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 13 QWK: ('QWK', 0.6807904596382552, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 14 QWK: ('QWK', 0.3878424789176541, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 15 QWK: ('QWK', 0.5702393923554109, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 16 QWK: ('QWK', 0.7506286457781807, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 17 QWK: ('QWK', 0.766511518216853, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 18 QWK: ('QWK', 0.7413615520526469, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 19 QWK: ('QWK', 0.6945813193560475, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 20 QWK: ('QWK', 0.7821971152428718, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Fold 1: Validation Loss = 0.40015730261802673, QWK = 0.7821971152428718\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 1 QWK: ('QWK', 0.579987195401954, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 2 QWK: ('QWK', 0.5754422464876123, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 3 QWK: ('QWK', 0.14717657851162358, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 4 QWK: ('QWK', 0.7491201476046465, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 5 QWK: ('QWK', 0.7064297630445792, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 6 QWK: ('QWK', 0.6952135372343077, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 7 QWK: ('QWK', 0.25990133836171525, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 8 QWK: ('QWK', 0.7598305409832689, True)\n",
            "109/109 [==============================] - 0s 4ms/step\n",
            "Epoch 9 QWK: ('QWK', 0.7162364870118267, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 10 QWK: ('QWK', 0.7403993299124632, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 11 QWK: ('QWK', 0.49630025436913106, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 12 QWK: ('QWK', 0.7021029739602893, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 13 QWK: ('QWK', 0.6710987581591058, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 14 QWK: ('QWK', 0.7467726995761202, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 15 QWK: ('QWK', 0.6061146585999069, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 16 QWK: ('QWK', 0.6255712337238981, True)\n",
            "109/109 [==============================] - 1s 4ms/step\n",
            "Epoch 17 QWK: ('QWK', 0.7763571499445323, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 18 QWK: ('QWK', 0.7579524711895094, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 19 QWK: ('QWK', 0.7597546409676528, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 20 QWK: ('QWK', 0.7843113285507399, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Fold 2: Validation Loss = 0.46749424934387207, QWK = 0.7843113285507399\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 1 QWK: ('QWK', 0.6243783889428425, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 2 QWK: ('QWK', 0.6714237894194416, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 3 QWK: ('QWK', 0.6658488788539929, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 4 QWK: ('QWK', 0.7436983741750411, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 5 QWK: ('QWK', 0.7439187990614125, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 6 QWK: ('QWK', 0.7297873017541585, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 7 QWK: ('QWK', 0.732004059730015, True)\n",
            "109/109 [==============================] - 1s 6ms/step\n",
            "Epoch 8 QWK: ('QWK', 0.7568814096654384, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 9 QWK: ('QWK', 0.7462989755560246, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 10 QWK: ('QWK', 0.7337168277766757, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 11 QWK: ('QWK', 0.7196538277622425, True)\n",
            "109/109 [==============================] - 1s 4ms/step\n",
            "Epoch 12 QWK: ('QWK', 0.775868747493171, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 13 QWK: ('QWK', 0.7710801949495134, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 14 QWK: ('QWK', 0.7551477144487554, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 15 QWK: ('QWK', 0.5987092692119628, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 16 QWK: ('QWK', 0.7011679323156315, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 17 QWK: ('QWK', 0.7843263133994751, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 18 QWK: ('QWK', 0.5584678902420559, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 19 QWK: ('QWK', 0.7378243355672793, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 20 QWK: ('QWK', 0.7637061122964802, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Fold 3: Validation Loss = 0.35983994603157043, QWK = 0.7637061122964802\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 1 QWK: ('QWK', 0.6835852117276292, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 2 QWK: ('QWK', 0.7141944177572572, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 3 QWK: ('QWK', 0.7448570328795161, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 4 QWK: ('QWK', 0.5853409983932767, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 5 QWK: ('QWK', 0.5696794431119124, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 6 QWK: ('QWK', 0.7573353014823544, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 7 QWK: ('QWK', 0.2645269633251941, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 8 QWK: ('QWK', 0.6851071005358038, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 9 QWK: ('QWK', 0.6625480283026538, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 10 QWK: ('QWK', 0.7214013544772246, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 11 QWK: ('QWK', 0.7608778736581282, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 12 QWK: ('QWK', 0.7547442017746787, True)\n",
            "109/109 [==============================] - 1s 5ms/step\n",
            "Epoch 13 QWK: ('QWK', 0.7576012218503212, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 14 QWK: ('QWK', 0.6771621378210076, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 15 QWK: ('QWK', 0.7509033116610316, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 16 QWK: ('QWK', 0.7445856788761092, True)\n",
            "109/109 [==============================] - 0s 4ms/step\n",
            "Epoch 17 QWK: ('QWK', 0.7819070550870428, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 18 QWK: ('QWK', 0.7780928338858502, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 19 QWK: ('QWK', 0.7416501575738823, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Epoch 20 QWK: ('QWK', 0.6895821681224782, True)\n",
            "109/109 [==============================] - 0s 3ms/step\n",
            "Fold 4: Validation Loss = 0.5165703296661377, QWK = 0.6895821681224782\n",
            "Validation score: 0.7560046303403325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mô hình Cat Boost Classifier**"
      ],
      "metadata": {
        "id": "fYQKzvk7xECr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation loop\n",
        "for fold in range(K):\n",
        "    # Initialize the CatBoost model\n",
        "    model = CatBoostRegressor(\n",
        "                learning_rate=0.05,\n",
        "                depth=5,\n",
        "                l2_leaf_reg=0.1,\n",
        "                iterations=700,\n",
        "                random_seed=42,\n",
        "                verbose=100)\n",
        "\n",
        "    # Calculate QWK parameters\n",
        "    a, b = calculate_qwk_parameters(train_feats[train_feats['fold'] != fold]['score'])\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train = train_feats[train_feats['fold'] != fold].drop(columns=drop_columns+target)\n",
        "    y_train = train_feats[train_feats['fold'] != fold]['score'] - a\n",
        "\n",
        "    X_eval = train_feats[train_feats['fold'] == fold].drop(columns=drop_columns+target)\n",
        "    y_eval = train_feats[train_feats['fold'] == fold]['score'] - a\n",
        "\n",
        "    print(f\"\\nTraining fold {fold} with a: {a}, b: {b}\")\n",
        "\n",
        "    # Create CatBoost Pool for training and validation sets\n",
        "    train_pool = Pool(X_train, y_train)\n",
        "    eval_pool = Pool(X_eval, y_eval)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_pool,\n",
        "        eval_set=eval_pool,\n",
        "        use_best_model=True\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    preds = model.predict(X_eval)\n",
        "\n",
        "    # Store actuals and predictions\n",
        "    actuals.extend(y_eval + a)\n",
        "    predictions.extend(np.round(preds + a, 0))\n",
        "\n",
        "# Calculate the QWK score for the predictions\n",
        "validation_score = cohen_kappa_score(actuals, predictions, weights=\"quadratic\")\n",
        "\n",
        "# Print the validation score\n",
        "print(f\"Validation score: {validation_score}\")"
      ],
      "metadata": {
        "id": "2nY0IMp50-Ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320c987c-657a-4434-ef99-cf3d11550bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training fold 0 with a: 2.9484, b: 1.0917\n",
            "0:\tlearn: 1.0201173\ttest: 1.0198884\tbest: 1.0198884 (0)\ttotal: 923ms\tremaining: 10m 44s\n",
            "100:\tlearn: 0.6149902\ttest: 0.6250033\tbest: 0.6250033 (100)\ttotal: 1m 10s\tremaining: 6m 56s\n",
            "200:\tlearn: 0.5666791\ttest: 0.5957363\tbest: 0.5957363 (200)\ttotal: 2m 21s\tremaining: 5m 51s\n",
            "300:\tlearn: 0.5303311\ttest: 0.5825729\tbest: 0.5825729 (300)\ttotal: 3m 30s\tremaining: 4m 38s\n",
            "400:\tlearn: 0.5040111\ttest: 0.5769648\tbest: 0.5769389 (399)\ttotal: 4m 37s\tremaining: 3m 26s\n",
            "500:\tlearn: 0.4817626\ttest: 0.5743250\tbest: 0.5742760 (499)\ttotal: 5m 43s\tremaining: 2m 16s\n",
            "600:\tlearn: 0.4624694\ttest: 0.5724112\tbest: 0.5724017 (595)\ttotal: 6m 50s\tremaining: 1m 7s\n",
            "699:\tlearn: 0.4450972\ttest: 0.5703836\tbest: 0.5702841 (695)\ttotal: 7m 54s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.5702840654\n",
            "bestIteration = 695\n",
            "\n",
            "Shrink model to first 696 iterations.\n",
            "\n",
            "Training fold 1 with a: 2.9482, b: 1.0914\n",
            "0:\tlearn: 1.0199240\ttest: 1.0207045\tbest: 1.0207045 (0)\ttotal: 787ms\tremaining: 9m 10s\n",
            "100:\tlearn: 0.6167365\ttest: 0.6222297\tbest: 0.6222297 (100)\ttotal: 1m 10s\tremaining: 6m 56s\n",
            "200:\tlearn: 0.5687201\ttest: 0.5899901\tbest: 0.5899901 (200)\ttotal: 2m 23s\tremaining: 5m 55s\n",
            "300:\tlearn: 0.5324083\ttest: 0.5743748\tbest: 0.5743748 (300)\ttotal: 3m 29s\tremaining: 4m 37s\n",
            "400:\tlearn: 0.5063739\ttest: 0.5683044\tbest: 0.5682916 (398)\ttotal: 4m 36s\tremaining: 3m 25s\n",
            "500:\tlearn: 0.4847481\ttest: 0.5650981\tbest: 0.5650981 (500)\ttotal: 5m 43s\tremaining: 2m 16s\n",
            "600:\tlearn: 0.4652657\ttest: 0.5625378\tbest: 0.5625378 (600)\ttotal: 6m 49s\tremaining: 1m 7s\n",
            "699:\tlearn: 0.4482062\ttest: 0.5611390\tbest: 0.5611390 (699)\ttotal: 7m 52s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.5611390201\n",
            "bestIteration = 699\n",
            "\n",
            "\n",
            "Training fold 2 with a: 2.9484, b: 1.092\n",
            "0:\tlearn: 1.0199170\ttest: 1.0200787\tbest: 1.0200787 (0)\ttotal: 805ms\tremaining: 9m 22s\n",
            "100:\tlearn: 0.6122046\ttest: 0.6435057\tbest: 0.6435057 (100)\ttotal: 1m 14s\tremaining: 7m 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mô hình Extreme Gradient Boosting (XGBoost)**"
      ],
      "metadata": {
        "id": "wRvYXZZ32d-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_qwk_list = []\n",
        "predictions, actuals = [], []\n",
        "\n",
        "for fold in range(K):\n",
        "    print('### Fold', fold+1)\n",
        "    a, b = calculate_qwk_parameters(train_feats[train_feats['fold'] != fold]['score'])\n",
        "    X_train = train_feats[train_feats[\"fold\"] != fold].drop(columns=drop_columns+target)\n",
        "    y_train = train_feats[train_feats[\"fold\"] != fold]['score'] - a\n",
        "    X_valid = train_feats[train_feats[\"fold\"] == fold].drop(columns=drop_columns+target)\n",
        "    y_valid = train_feats[train_feats[\"fold\"] == fold]['score'] - a\n",
        "\n",
        "    model = XGBRegressor(objective = qwk_objective)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    train_preds = model.predict(X_valid)\n",
        "    actuals.extend(y_valid + a)\n",
        "    predictions.extend(np.round(train_preds + a, 0))\n",
        "\n",
        "    score_qwk_list.append(calculate_quadratic_weighted_kappa(y_valid, train_preds)[1])\n",
        "    print(f\"QWK score: {score_qwk_list[-1]}\")\n",
        "    print()\n",
        "\n",
        "validation_score = cohen_kappa_score(actuals, predictions, weights=\"quadratic\")\n",
        "print(f\"Validation score: {validation_score}\")"
      ],
      "metadata": {
        "id": "Mg-ZeA4_2dxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mô hình Light Gradient-Boosting Machine**\n"
      ],
      "metadata": {
        "id": "ZQHtZtSGAft_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_models = []\n",
        "predictions, actuals = [], []\n",
        "\n",
        "# Định nghĩa các callback cho LightGBM\n",
        "training_callbacks = [\n",
        "    lgb.log_evaluation(period=25),\n",
        "    lgb.early_stopping(stopping_rounds=75, first_metric_only=True)\n",
        "]\n",
        "\n",
        "# Huấn luyện mô hình với Cross-Validation\n",
        "for fold in range(K):\n",
        "\n",
        "    model = lgb.LGBMRegressor(\n",
        "                objective = qwk_objective,\n",
        "                metrics = 'None',\n",
        "                learning_rate = 0.05,\n",
        "                max_depth = 5,\n",
        "                num_leaves = 10,\n",
        "                colsample_bytree=0.3,\n",
        "                reg_alpha = 0.7,\n",
        "                reg_lambda = 0.1,\n",
        "                n_estimators=700,\n",
        "                random_state=42,\n",
        "                extra_trees=True,\n",
        "                class_weight='balanced',\n",
        "                verbosity = - 1)\n",
        "\n",
        "    a, b = calculate_qwk_parameters(train_feats[train_feats['fold'] != fold]['score'])\n",
        "    # Tách dữ liệu huấn luyện và đánh giá cho từng fold\n",
        "    X_train = train_feats[train_feats['fold'] != fold].drop(columns=drop_columns+target)\n",
        "    y_train = train_feats[train_feats['fold'] != fold]['score'] - a\n",
        "\n",
        "    X_eval = train_feats[train_feats['fold'] == fold].drop(columns=drop_columns+target)\n",
        "    y_eval = train_feats[train_feats['fold'] == fold]['score'] - a\n",
        "\n",
        "    print(f\"\\nTraining fold {fold} with a: {a}, b: {b}\")\n",
        "\n",
        "    # Huấn luyện mô hình\n",
        "    lgb_model = model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_names=['train', 'valid'],\n",
        "        eval_set=[(X_train, y_train), (X_eval, y_eval)],\n",
        "        eval_metric=calculate_quadratic_weighted_kappa,\n",
        "        callbacks=training_callbacks\n",
        "    )\n",
        "\n",
        "    lgb_models.append(lgb_model)\n",
        "\n",
        "    # Dự đoán\n",
        "    pred = model.predict(X_eval)\n",
        "    actuals.extend(y_eval + a)\n",
        "    predictions.extend(np.round(pred + a, 0))\n",
        "\n",
        "# Tính toán điểm Kappa trọng số bậc hai (QWK) cho các dự đoán\n",
        "validation_score = cohen_kappa_score(actuals, predictions, weights=\"quadratic\")\n",
        "# In ra điểm đánh giá\n",
        "print(f\"Validation score: {validation_score}\")"
      ],
      "metadata": {
        "id": "u-szdaj6_p6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kết luận:** Nhóm nhận thấy mô hình **Light Gradient-Boosting Machine** cho ra kết quả tốt nhất, nên sẽ sử dụng mô hình này để dự đoán kết quả cuối cùng."
      ],
      "metadata": {
        "id": "GZkaR-k8HTiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Dự đoán kết quả**"
      ],
      "metadata": {
        "id": "ZPgbTxFBAQjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Danh sách để lưu trữ dự đoán từ các mô hình\n",
        "test_predictions = []\n",
        "drop_columns = ['essay_id']\n",
        "\n",
        "# Lặp qua từng mô hình để dự đoán trên tập dữ liệu kiểm thử\n",
        "for fold, model in enumerate(lgb_models):\n",
        "    X_test = test_feats.drop(columns=drop_columns)\n",
        "    fold_predictions = model.predict(X_test) + a\n",
        "    test_predictions.append(fold_predictions)\n",
        "\n",
        "# Kết hợp kết quả từ các mô hình\n",
        "for i, fold_predictions in enumerate(test_predictions):\n",
        "    test_feats[f\"score_pred_{i}\"] = fold_predictions\n",
        "\n",
        "# Tính toán giá trị dự đoán trung bình và làm tròn kết quả để ra kết quả cuối cùng\n",
        "test_feats[\"score\"] = np.round(test_feats[[f\"score_pred_{fold}\" for fold in range(K)]].mean(axis=1), 0).astype('int32')\n",
        "\n",
        "# In ra các giá trị dự đoán\n",
        "test_feats[['essay_id', 'score']].head()"
      ],
      "metadata": {
        "id": "41wbG4fnAZKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}