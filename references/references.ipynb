{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008083,"end_time":"2024-05-13T19:16:47.363019","exception":false,"start_time":"2024-05-13T19:16:47.354936","status":"completed"},"tags":[]},"source":["# RAPIDS SVR - CV 0.830\n","This notebook is a RAPIDS SVR starter notebook which achieves CV 0.830 and LB ???. (Let's submit to LB and see what score it achieves).\n","\n","In this notebook, we extract text embeddings from 6 Hugging Face models. We **do not** finetune any LLM. The 6 LLM that we use here are models directly downloaded from Hugging Face (in notebook [here][1]) as is. Each of these model can accept token lengths of at least 1024 as discussed [here][3]. Therefore we can input the full essay instead of breaking into 512 chunks.\n","\n","We extract 6 sets of embeddings and concatenate them into 5376 features! Afterward we use RAPIDS SVR to quickly train a 15-Fold support vector regression model on Kaggle's 2xT4 GPUs.\n","\n","Then we apply threshold post process to convert the regression outputs into the 6 possible target labels of 1, 2, 3, 4, 5, 6 as discussed by MPWare [here][2]\n","\n","[1]: https://www.kaggle.com/code/cdeotte/download-huggingface-models\n","[2]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/502279\n","[3]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/498571"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007393,"end_time":"2024-05-13T19:16:47.378261","exception":false,"start_time":"2024-05-13T19:16:47.370868","status":"completed"},"tags":[]},"source":["# Fix RAPIDS Installation\n","To make RAPIDS work in a Kaggle notebook we need to do one of the following:\n","* Downgrade Pandas to 1.X\n","* Pip install the latest RAPIDS\n","\n","I will do the first option since it is faster and RAPIDS v23.08.00 is recent enough for our SVR in this notebook. An example of pip install recent RAPIDS v24.02.00 is [here][1]\n","\n","[1]: https://www.kaggle.com/code/premsagar/rapids-cudf-pandas-on-kaggle"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-13T19:16:47.395485Z","iopub.status.busy":"2024-05-13T19:16:47.394763Z","iopub.status.idle":"2024-05-13T19:17:32.292915Z","shell.execute_reply":"2024-05-13T19:17:32.291764Z"},"papermill":{"duration":44.909529,"end_time":"2024-05-13T19:17:32.295355","exception":false,"start_time":"2024-05-13T19:16:47.385826","status":"completed"},"tags":[]},"outputs":[],"source":["# !pip install --find-links /kaggle/input/downgrade-pandas /kaggle/input/downgrade-pandas/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.012248,"end_time":"2024-05-13T19:17:32.316881","exception":false,"start_time":"2024-05-13T19:17:32.304633","status":"completed"},"tags":[]},"source":["# Load Libraries and Data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:32.334977Z","iopub.status.busy":"2024-05-13T19:17:32.334656Z","iopub.status.idle":"2024-05-13T19:17:33.590753Z","shell.execute_reply":"2024-05-13T19:17:33.589782Z"},"papermill":{"duration":1.267719,"end_time":"2024-05-13T19:17:33.592756","exception":false,"start_time":"2024-05-13T19:17:32.325037","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n","\n","import numpy as np, gc, re \n","import pandas as pd "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './data/train.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train.csv'"]}],"source":["train = pd.read_csv('./data/train.csv')\n","train.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>essay_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000d118</td>\n","      <td>Many people have car where they live. The thin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000fe60</td>\n","      <td>I am a scientist at NASA that is discussing th...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>001ab80</td>\n","      <td>People always wish they had the same technolog...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  essay_id                                          full_text\n","0  000d118  Many people have car where they live. The thin...\n","1  000fe60  I am a scientist at NASA that is discussing th...\n","2  001ab80  People always wish they had the same technolog..."]},"metadata":{},"output_type":"display_data"}],"source":["test = pd.read_csv('./learning-agency-lab-automated-essay-scoring-2/test.csv')\n","test.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008383,"end_time":"2024-05-13T19:17:33.610024","exception":false,"start_time":"2024-05-13T19:17:33.601641","status":"completed"},"tags":[]},"source":["# Stratified 15 K Fold"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:33.629869Z","iopub.status.busy":"2024-05-13T19:17:33.629071Z","iopub.status.idle":"2024-05-13T19:17:34.834928Z","shell.execute_reply":"2024-05-13T19:17:34.834029Z"},"papermill":{"duration":1.218633,"end_time":"2024-05-13T19:17:34.837061","exception":false,"start_time":"2024-05-13T19:17:33.618428","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train samples per fold:\n"]},{"data":{"text/plain":["0     1154\n","1     1154\n","2     1154\n","3     1154\n","4     1154\n","5     1154\n","6     1154\n","7     1154\n","8     1154\n","9     1154\n","10    1154\n","11    1154\n","12    1153\n","13    1153\n","14    1153\n","Name: fold, dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import StratifiedKFold\n","\n","FOLDS = 15\n","train[\"fold\"] = -1\n","skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n","for fold,(train_index, val_index) in enumerate(skf.split(train,train[\"score\"])):\n","    train.loc[val_index,\"fold\"] = fold\n","print('Train samples per fold:')\n","train.fold.value_counts().sort_index()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008867,"end_time":"2024-05-13T19:17:34.854859","exception":false,"start_time":"2024-05-13T19:17:34.845992","status":"completed"},"tags":[]},"source":["# Generate Embeddings"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:34.874546Z","iopub.status.busy":"2024-05-13T19:17:34.873639Z","iopub.status.idle":"2024-05-13T19:17:41.584345Z","shell.execute_reply":"2024-05-13T19:17:41.583543Z"},"papermill":{"duration":6.722973,"end_time":"2024-05-13T19:17:41.586735","exception":false,"start_time":"2024-05-13T19:17:34.863762","status":"completed"},"tags":[]},"outputs":[],"source":["from transformers import AutoModel,AutoTokenizer\n","import torch, torch.nn.functional as F\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:41.606261Z","iopub.status.busy":"2024-05-13T19:17:41.60581Z","iopub.status.idle":"2024-05-13T19:17:41.611374Z","shell.execute_reply":"2024-05-13T19:17:41.610552Z"},"papermill":{"duration":0.017389,"end_time":"2024-05-13T19:17:41.613232","exception":false,"start_time":"2024-05-13T19:17:41.595843","status":"completed"},"tags":[]},"outputs":[],"source":["def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output.last_hidden_state.detach().cpu()\n","    input_mask_expanded = (\n","        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    )\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n","        input_mask_expanded.sum(1), min=1e-9\n","    )"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:41.631385Z","iopub.status.busy":"2024-05-13T19:17:41.63111Z","iopub.status.idle":"2024-05-13T19:17:41.637907Z","shell.execute_reply":"2024-05-13T19:17:41.637039Z"},"papermill":{"duration":0.017943,"end_time":"2024-05-13T19:17:41.6398","exception":false,"start_time":"2024-05-13T19:17:41.621857","status":"completed"},"tags":[]},"outputs":[],"source":["class EmbedDataset(torch.utils.data.Dataset):\n","    def __init__(self,df,tokenizer,max_length):\n","        self.df = df.reset_index(drop=True)\n","        self.tokenizer = tokenizer\n","        self.max = max_length\n","    def __len__(self):\n","        return len(self.df)\n","    def __getitem__(self,idx):\n","        text = self.df.loc[idx,\"full_text\"]\n","        tokens = self.tokenizer(\n","                text,\n","                None,\n","                add_special_tokens=True,\n","                padding='max_length',\n","                truncation=True,\n","                max_length=self.max,\n","                return_tensors=\"pt\")\n","        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n","        return tokens"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008495,"end_time":"2024-05-13T19:17:41.656901","exception":false,"start_time":"2024-05-13T19:17:41.648406","status":"completed"},"tags":[]},"source":["# Extract Embeddings"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:41.675807Z","iopub.status.busy":"2024-05-13T19:17:41.675474Z","iopub.status.idle":"2024-05-13T19:17:41.690029Z","shell.execute_reply":"2024-05-13T19:17:41.68911Z"},"papermill":{"duration":0.026311,"end_time":"2024-05-13T19:17:41.691963","exception":false,"start_time":"2024-05-13T19:17:41.665652","status":"completed"},"tags":[]},"outputs":[],"source":["def get_embeddings(model_name='', max_length=1024, batch_size=32, compute_train=True, compute_test=True):\n","\n","    global train, test\n","\n","    DEVICE = \"cuda:1\" # EXTRACT EMBEDDINGS WITH GPU #2\n","    path = \"/kaggle/input/download-huggingface-models/\"\n","    disk_name = path + model_name.replace(\"/\",\"_\")\n","    model = AutoModel.from_pretrained( disk_name , trust_remote_code=True)\n","    tokenizer = AutoTokenizer.from_pretrained( disk_name , trust_remote_code=True)\n","\n","    ds_tr = EmbedDataset(train, tokenizer, max_length)\n","    embed_dataloader_tr = torch.utils.data.DataLoader(ds_tr,\n","                            batch_size=batch_size,\n","                            shuffle=False)\n","    ds_te = EmbedDataset(test, tokenizer, max_length)\n","    embed_dataloader_te = torch.utils.data.DataLoader(ds_te,\n","                            batch_size=batch_size,\n","                            shuffle=False)\n","    \n","    model = model.to(DEVICE)\n","    model.eval()\n","\n","    # COMPUTE TRAIN EMBEDDINGS\n","    all_train_text_feats = []\n","    if compute_train:\n","        for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n","            input_ids = batch[\"input_ids\"].to(DEVICE)\n","            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n","            with torch.no_grad():\n","                with torch.cuda.amp.autocast(enabled=True):\n","                    model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n","            sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n","            # Normalize the embeddings\n","            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n","            sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n","            all_train_text_feats.extend(sentence_embeddings)\n","    all_train_text_feats = np.array(all_train_text_feats)\n","\n","    # COMPUTE TEST EMBEDDINGS\n","    all_test_text_feats = []\n","    if compute_test:\n","        for batch in embed_dataloader_te:\n","            input_ids = batch[\"input_ids\"].to(DEVICE)\n","            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n","            with torch.no_grad():\n","                with torch.cuda.amp.autocast(enabled=True):\n","                    model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n","            sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n","            # Normalize the embeddings\n","            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n","            sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n","            all_test_text_feats.extend(sentence_embeddings)\n","        all_test_text_feats = np.array(all_test_text_feats)\n","    all_test_text_feats = np.array(all_test_text_feats)\n","\n","    # CLEAR MEMORY\n","    del ds_tr, ds_te\n","    del embed_dataloader_tr, embed_dataloader_te\n","    del model, tokenizer\n","    del model_output, sentence_embeddings, input_ids, attention_mask\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    # RETURN EMBEDDINGS\n","    return all_train_text_feats, all_test_text_feats"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:41.711285Z","iopub.status.busy":"2024-05-13T19:17:41.710938Z","iopub.status.idle":"2024-05-13T19:17:41.715989Z","shell.execute_reply":"2024-05-13T19:17:41.715098Z"},"papermill":{"duration":0.016991,"end_time":"2024-05-13T19:17:41.717967","exception":false,"start_time":"2024-05-13T19:17:41.700976","status":"completed"},"tags":[]},"outputs":[],"source":["# EMBEDDINGS TO LOAD/COMPUTE\n","# PARAMETERS = (MODEL_NAME, MAX_LENGTH, BATCH_SIZE)\n","# CHOOSE LARGEST BATCH SIZE WITHOUT MEMORY ERROR\n","\n","models = [\n","    ('microsoft/deberta-base', 1024, 32),\n","    ('microsoft/deberta-large', 1024, 8),\n","    ('microsoft/deberta-v3-large', 1024, 8),\n","    ('allenai/longformer-base-4096', 1024, 32),\n","    ('google/bigbird-roberta-base', 1024, 32),\n","    ('google/bigbird-roberta-large', 1024, 8),\n","]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:17:41.737122Z","iopub.status.busy":"2024-05-13T19:17:41.736844Z","iopub.status.idle":"2024-05-13T19:18:33.11327Z","shell.execute_reply":"2024-05-13T19:18:33.112296Z"},"papermill":{"duration":51.388457,"end_time":"2024-05-13T19:18:33.115494","exception":false,"start_time":"2024-05-13T19:17:41.727037","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Computing train embeddings for /kaggle/input/essay-embeddings-v1/microsoft_deberta-base.npy\n"]},{"ename":"OSError","evalue":"Incorrect path_or_model_id: '/kaggle/input/download-huggingface-models/microsoft_deberta-base'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/transformers/utils/hub.py:399\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/input/download-huggingface-models/microsoft_deberta-base'. Use `repo_type` argument if needed.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing train embeddings for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     train_embed, test_embed \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(name, train_embed)\n\u001b[1;32m     15\u001b[0m all_train_embeds\u001b[38;5;241m.\u001b[39mappend(train_embed)\n","Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(model_name, max_length, batch_size, compute_train, compute_test)\u001b[0m\n\u001b[1;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/download-huggingface-models/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m disk_name \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m model_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisk_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained( disk_name , trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m ds_tr \u001b[38;5;241m=\u001b[39m EmbedDataset(train, tokenizer, max_length)\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:484\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/min_ds-env/lib/python3.10/site-packages/transformers/utils/hub.py:463\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/kaggle/input/download-huggingface-models/microsoft_deberta-base'. Please provide either the path to a local folder or the repo_id of a model on the Hub."]}],"source":["path = \"/kaggle/input/essay-embeddings-v1/\"\n","all_train_embeds = []\n","all_test_embeds = []\n","\n","for (model, max_length, batch_size) in models:\n","    name = path + model.replace(\"/\",\"_\") + \".npy\"\n","    if os.path.exists(name):\n","        _, test_embed = get_embeddings(model_name=model, max_length=max_length, batch_size=batch_size, compute_train=False)\n","        train_embed = np.load(name)\n","        print(f\"Loading train embeddings for {name}\")\n","    else:\n","        print(f\"Computing train embeddings for {name}\")\n","        train_embed, test_embed = get_embeddings(model_name=model, max_length=max_length, batch_size=batch_size, compute_train=True)\n","        np.save(name, train_embed)\n","    all_train_embeds.append(train_embed)\n","    all_test_embeds.append(test_embed)\n","\n","del train_embed, test_embed"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008934,"end_time":"2024-05-13T19:18:33.13384","exception":false,"start_time":"2024-05-13T19:18:33.124906","status":"completed"},"tags":[]},"source":["# Combine Feature Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:18:33.153616Z","iopub.status.busy":"2024-05-13T19:18:33.153139Z","iopub.status.idle":"2024-05-13T19:18:33.397856Z","shell.execute_reply":"2024-05-13T19:18:33.396895Z"},"papermill":{"duration":0.257046,"end_time":"2024-05-13T19:18:33.40012","exception":false,"start_time":"2024-05-13T19:18:33.143074","status":"completed"},"tags":[]},"outputs":[],"source":["all_train_embeds = np.concatenate(all_train_embeds,axis=1)\n","all_test_embeds = np.concatenate(all_test_embeds,axis=1)\n","\n","gc.collect()\n","print('Our concatenated train embeddings have shape', all_train_embeds.shape )"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010034,"end_time":"2024-05-13T19:18:33.419647","exception":false,"start_time":"2024-05-13T19:18:33.409613","status":"completed"},"tags":[]},"source":["# Train RAPIDS cuML SVR\n","Documentation for RAPIDS SVR is [here][1]. Using RAPIDS support vector regression (SVR) is a great model when we have 1000s of features because it is quick and it naturally will perform feature selection and remove features to prevent overfitting.\n","\n","Note that SVR model likes the inputs to be standardized so that each feature is rougly mean 0 and std 1. We approximate this by performing L2 norm on the extracted embeddings.\n","\n","[1]: https://docs.rapids.ai/api/cuml/stable/api.html#support-vector-machines"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:18:33.439426Z","iopub.status.busy":"2024-05-13T19:18:33.439158Z","iopub.status.idle":"2024-05-13T19:18:39.286857Z","shell.execute_reply":"2024-05-13T19:18:39.285803Z"},"papermill":{"duration":5.860218,"end_time":"2024-05-13T19:18:39.289139","exception":false,"start_time":"2024-05-13T19:18:33.428921","status":"completed"},"tags":[]},"outputs":[],"source":["from cuml.svm import SVR\n","import cuml\n","print('RAPIDS version',cuml.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:18:39.310531Z","iopub.status.busy":"2024-05-13T19:18:39.310001Z","iopub.status.idle":"2024-05-13T19:19:07.772972Z","shell.execute_reply":"2024-05-13T19:19:07.771712Z"},"papermill":{"duration":28.475824,"end_time":"2024-05-13T19:19:07.77502","exception":false,"start_time":"2024-05-13T19:18:39.299196","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.metrics import cohen_kappa_score\n","\n","oof = np.zeros(len(train), dtype='float32')\n","test_preds = np.zeros((len(test),FOLDS), dtype='float32')\n","\n","def comp_score(y_true,y_pred):\n","    p = y_pred.clip(1,6).round(0)\n","    m = cohen_kappa_score(y_true, p, weights='quadratic')\n","    return m\n","\n","for fold in range(FOLDS):\n","    print('#'*25)\n","    print('### Fold',fold+1)\n","    print('#'*25)\n","    \n","    train_index = train[\"fold\"] != fold\n","    valid_index = train[\"fold\"] == fold\n","    \n","    X_train = all_train_embeds[train_index,]\n","    y_train = train.loc[train_index,'score'].values\n","    X_valid = all_train_embeds[valid_index,]\n","    y_valid = train.loc[valid_index,'score'].values\n","    X_test = all_test_embeds\n","    \n","    model = SVR(C=10)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_valid)\n","    test_preds[:,fold] = model.predict(X_test)\n","    oof[valid_index] = preds\n","\n","    score = comp_score(y_valid, preds)    \n","    print(f\"=> QWK score: {score}\")\n","    print()\n","    \n","print('#'*25)\n","score = comp_score(train.score.values, oof)\n","print('Overall CV QWK score =',score)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011076,"end_time":"2024-05-13T19:19:07.797436","exception":false,"start_time":"2024-05-13T19:19:07.78636","status":"completed"},"tags":[]},"source":["# Find QWK Thresholds\n","The target labels are 1,2,3,4,5,6. So there are 5 thresholds. There is a threshold to decide between prediction 1 versus 2. For example if we have regression prediction 1.3, should it become final target 1 or 2? Where should the cutoff be?\n","\n","The algorithm below determines that 1.749 is the optimal cutoff for our SVR in this notebook. A different model may have different optimal threshold. This threshold says when regression prediction is between 0 and 1.749 then we predict 1. And when regression prediction is between 1.749 and the next threshold of 2.533 then we predict 2. The other thresholds decide when to predict 3,4,5,6."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:19:07.820551Z","iopub.status.busy":"2024-05-13T19:19:07.820215Z","iopub.status.idle":"2024-05-13T19:19:07.847325Z","shell.execute_reply":"2024-05-13T19:19:07.846569Z"},"papermill":{"duration":0.041129,"end_time":"2024-05-13T19:19:07.849209","exception":false,"start_time":"2024-05-13T19:19:07.80808","status":"completed"},"tags":[]},"outputs":[],"source":["def find_thresholds(true, pred, steps=50):\n","\n","    # SAVE TRIALS FOR PLOTTING\n","    xs = [[],[],[],[],[]]\n","    ys = [[],[],[],[],[]]\n","\n","    # COMPUTE BASELINE METRIC\n","    threshold = [1.5, 2.5, 3.5, 4.5, 5.5]\n","    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n","                    labels=[1,2,3,4,5,6]).astype('int32')\n","    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n","\n","    # FIND FIVE OPTIMAL THRESHOLDS\n","    for k in range(5):\n","        for sign in [1,-1]:\n","            v = threshold[k]\n","            threshold2 = threshold.copy()\n","            stop = 0\n","            while stop<steps:\n","\n","                # TRY NEW THRESHOLD\n","                v += sign * 0.001\n","                threshold2[k] = v\n","                pred2 = pd.cut(pred, [-np.inf] + threshold2 + [np.inf], \n","                                labels=[1,2,3,4,5,6]).astype('int32')\n","                metric = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n","\n","                # SAVE TRIALS FOR PLOTTING\n","                xs[k].append(v)\n","                ys[k].append(metric)\n","\n","                # EARLY STOPPING\n","                if metric<=best:\n","                    stop += 1\n","                else:\n","                    stop = 0\n","                    best = metric\n","                    threshold = threshold2.copy()\n","\n","    # COMPUTE FINAL METRIC\n","    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n","                    labels=[1,2,3,4,5,6]).astype('int32')\n","    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")   \n","\n","    # RETURN RESULTS\n","    threshold = [np.round(t,3) for t in threshold]\n","    return best, threshold, xs, ys"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:19:07.872024Z","iopub.status.busy":"2024-05-13T19:19:07.87171Z","iopub.status.idle":"2024-05-13T19:20:58.540933Z","shell.execute_reply":"2024-05-13T19:20:58.53988Z"},"papermill":{"duration":110.693874,"end_time":"2024-05-13T19:20:58.553785","exception":false,"start_time":"2024-05-13T19:19:07.859911","status":"completed"},"tags":[]},"outputs":[],"source":["best, thresholds, xs, ys = find_thresholds(train.score.values, oof, steps=500)\n","print('Best thresholds are:', thresholds )\n","print('=> achieve Overall CV QWK score =', best )"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010983,"end_time":"2024-05-13T19:20:58.575958","exception":false,"start_time":"2024-05-13T19:20:58.564975","status":"completed"},"tags":[]},"source":["# Display Threshold Trials\n","Below we observe the result of different thresholds and resultant CV QWK score. We note that the curves are pretty smooth which is good. If it is too bumpy, then the bumps are most likely random and will not generalize to unseen test data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:20:58.598624Z","iopub.status.busy":"2024-05-13T19:20:58.598288Z","iopub.status.idle":"2024-05-13T19:21:00.106553Z","shell.execute_reply":"2024-05-13T19:21:00.105666Z"},"papermill":{"duration":1.522249,"end_time":"2024-05-13T19:21:00.108914","exception":false,"start_time":"2024-05-13T19:20:58.586665","status":"completed"},"tags":[]},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","diff = 0.5\n","for k in range(5):\n","    plt.figure(figsize=(10,3))\n","    plt.scatter(xs[k],ys[k],s=3)\n","    m = k+1.5\n","    plt.xlim((m-diff,m+diff))\n","    i = np.where( (np.array(xs[k])>m-diff)&(np.array(xs[k])<m+diff) )[0]\n","    mn = np.min(np.array(ys[k])[i])\n","    mx = np.max(np.array(ys[k])[i])\n","    plt.ylim((mn,mx))\n","    \n","    plt.plot([thresholds[k],thresholds[k]],[mn,mx],'--',\n","             color='black', label='optimal threshold')\n","    \n","    plt.title(f\"Threshold between {k+1} and {k+2}\",size=16)\n","    plt.xlabel('Threshold value',size=10)\n","    plt.ylabel('QWK CV score',size=10)\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013187,"end_time":"2024-05-13T19:21:00.135815","exception":false,"start_time":"2024-05-13T19:21:00.122628","status":"completed"},"tags":[]},"source":["# Create Submission CSV\n","We average our 15 fold predictions and apply optimal thresholds above to convert the 15 sets of regression predictions into 1 set of final target predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:21:00.163381Z","iopub.status.busy":"2024-05-13T19:21:00.163088Z","iopub.status.idle":"2024-05-13T19:21:00.168421Z","shell.execute_reply":"2024-05-13T19:21:00.167541Z"},"papermill":{"duration":0.021494,"end_time":"2024-05-13T19:21:00.170466","exception":false,"start_time":"2024-05-13T19:21:00.148972","status":"completed"},"tags":[]},"outputs":[],"source":["test_preds = np.mean(test_preds,axis=1)\n","print('Test preds shape:', test_preds.shape )\n","print('First 3 test preds:',test_preds[:3] )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:21:00.198184Z","iopub.status.busy":"2024-05-13T19:21:00.197872Z","iopub.status.idle":"2024-05-13T19:21:00.205168Z","shell.execute_reply":"2024-05-13T19:21:00.204207Z"},"papermill":{"duration":0.023285,"end_time":"2024-05-13T19:21:00.207086","exception":false,"start_time":"2024-05-13T19:21:00.183801","status":"completed"},"tags":[]},"outputs":[],"source":["test_preds_pp = pd.cut(test_preds, [-np.inf] + thresholds + [np.inf], \n","                       labels=[1,2,3,4,5,6]).astype('int32')\n","print('First 3 test preds after PP:',test_preds_pp[:3] )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T19:21:00.23704Z","iopub.status.busy":"2024-05-13T19:21:00.236706Z","iopub.status.idle":"2024-05-13T19:21:00.255327Z","shell.execute_reply":"2024-05-13T19:21:00.254466Z"},"papermill":{"duration":0.035365,"end_time":"2024-05-13T19:21:00.257232","exception":false,"start_time":"2024-05-13T19:21:00.221867","status":"completed"},"tags":[]},"outputs":[],"source":["sub = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\n","sub[\"score\"] = test_preds_pp\n","sub.score = sub.score.astype('int32')\n","sub.to_csv(\"submission.csv\",index=False)\n","print(\"Submission shape\", sub.shape )\n","sub.head()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8059942,"sourceId":71485,"sourceType":"competition"},{"datasetId":5000565,"sourceId":8403792,"sourceType":"datasetVersion"},{"sourceId":177473688,"sourceType":"kernelVersion"},{"sourceId":177475777,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"papermill":{"default_parameters":{},"duration":258.371239,"end_time":"2024-05-13T19:21:02.799575","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-13T19:16:44.428336","version":"2.3.4"}},"nbformat":4,"nbformat_minor":4}
